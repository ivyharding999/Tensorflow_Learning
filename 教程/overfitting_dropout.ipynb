{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "d:\\python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train.shape=(1257, 64)\\n   y_train.shape=(1257, 10)\\n   X_test.shape=(540, 64)\\n   y_test.shape=(540, 10)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "digits = load_digits()\n",
    "X = digits.data  ##X.shape:(1797, 64)\n",
    "y = digits.target  ##y.shape:(1797,).. y=array([0, 1, 2, ..., 8, 9, 8])\n",
    "y = LabelBinarizer().fit_transform(y)   \n",
    "'''###这个操作是把y改成One——hot类型  y.shape: (1797, 10)   \n",
    "   y=array([[1, 0, 0, ..., 0, 0, 0],\n",
    "           [0, 1, 0, ..., 0, 0, 0],\n",
    "           [0, 0, 1, ..., 0, 0, 0],\n",
    "                ...,\n",
    "           [0, 0, 0, ..., 0, 1, 0],\n",
    "           [0, 0, 0, ..., 0, 0, 1],\n",
    "           [0, 0, 0, ..., 0, 1, 0]])'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "'''X_train.shape=(1257, 64)\n",
    "   y_train.shape=(1257, 10)\n",
    "   X_test.shape=(540, 64)\n",
    "   y_test.shape=(540, 10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs,in_size,out_size,n_layer,activation_function=None):\n",
    "    layer_name='layer%s'%n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size,out_size],dtype=tf.float32),name='W')##设权重初始值为随机生成的矩阵\n",
    "            tf.summary.histogram(layer_name+'/weights',Weights)  ##通过histogram显示\n",
    "        with tf.name_scope('biases'):   \n",
    "            biases = tf.Variable(tf.zeros([1,out_size])+0.1,name='b')  ##机器学习中推荐偏置初始值不为0,为什么是一行，n_out列，为啥不是反过来？？？\n",
    "            tf.summary.histogram(layer_name+'/biases',biases)\n",
    "            ###回答此问题，可以看看下面的公式\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs,Weights),biases)### x*W+B\n",
    "            Wx_plus_b = tf.nn.dropout(Wx_plus_b,keep_prob)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "        tf.summary.histogram(layer_name+'/outputs',outputs)###这个貌似是和后面的loss那边的tf.summary.scalar()是配套使用的\n",
    "        return outputs     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###define placeholder for inputs to network\n",
    "keep_prob = tf.placeholder(tf.float32)  ###定义丢掉率\n",
    "xs = tf.placeholder(tf.float32,[None,64])  ###8*8=64,None表示其值大小不定，在这里作为第一个维度值，用以指代batch的大小，意即x的数量不定\n",
    "ys = tf.placeholder(tf.float32,[None,10])  ##10类输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add output layer\n",
    "l1 = add_layer(xs,64,100,n_layer=1,activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l1,100,10,n_layer=2,activation_function = tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the loss between predition and real data \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))##loss\n",
    "tf.summary.scalar('loss',cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()  ##合并之前的所有变量\n",
    "train_writer = tf.summary.FileWriter(\"logs/train\",sess.graph)\n",
    "test_writer = tf.summary.FileWriter(\"logs/test\",sess.graph)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train_step,feed_dict={xs:X_train,ys:y_train,keep_prob:0.5})  ##保持50%的概率不被丢掉。。如果keep_prob=0.6，保持60%的概率不被丢掉，也就是丢掉了40%\n",
    "    if i % 50 == 0:\n",
    "        ##record loss\n",
    "        train_result = sess.run(merged,feed_dict={xs:X_train,ys:y_train,keep_prob:1})##这里我并不想丢掉任何数据\n",
    "        test_result = sess.run(merged,feed_dict={xs:X_test,ys:y_test,keep_prob:1})\n",
    "        train_writer.add_summary(train_result,i)\n",
    "        test_writer.add_summary(test_result,i)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
